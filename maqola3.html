<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>USE OF OPTIMIZERS IN MODELS</title>

  <!-- Scholar citation meta tags -->
  <meta name="citation_title" content="USE OF OPTIMIZERS IN MODELS">
  <meta name="citation_author" content="A. D. Madaminjonov">
  <meta name="citation_author" content="A. E. Rashidov">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="Innovative teaching techniques in physics, mathematics, vocational and mechanical training: XVI International Scientific-Practical Conference">
  <meta name="citation_pdf_url" content="https://teacherare.github.io/maqolalar/maqola3.pdf">
  <!-- References (from maqola3.pdf) -->
<meta name="citation_reference" content="author=Gupta, A; title=A comprehensive guide on optimizers in deep learning; publisher=Analytics Vidhya; year=2023; url=https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/">
<meta name="citation_reference" content="author=Axatov A.R.; author=Rashidov A.E.; title=Improving the efficiency of intellectual analysis using the correlation coefficient; publisher=Raqamli ta‚Äòlim texnologiyalari: amaliyot, tajriba, muammo va istiqbollari (Respublika ilmiy-amaliy anjumani); year=2023; pages=213‚Äì216">
<meta name="citation_reference" content="author=Akhatov A.; author=Rashidov A.; author=Renavikar A.; title=Optimization of the database structure based on Machine Learning algorithms in case of increased data flow; conference=International Conference on Artificial Intelligence, Blockchain, Computing and Security (ICABCS 2023); year=2023; pages=675‚Äì681">
<meta name="citation_reference" content="author=Musstafa; title=Optimizers in Deep Learning - MLearning.ai - Medium; publisher=Medium; year=2022; url=https://medium.com/mlearning-ai/optimizers-in-deep-learning-7bf81fed78a0">
<meta name="citation_reference" content="author=Axatov A.R.; author=Rashidov A.E.; author=Nazarov F.M.; author=Renavikar A.; title=Optimization of the number of databases in the Big Data processing; journal=–ü—Ä–æ–±–ª–µ–º—ã –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏; year=2023; issue=1(58); doi=10.24412/2073-0667-2023-1-33-47">
<meta name="citation_reference" content="author=Brownlee, J; title=A gentle introduction to Mini-Batch Gradient Descent and how to configure batch size; publisher=MachineLearningMastery.com; year=2019; url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/">
<meta name="citation_reference" content="author=Bushaev, V; title=Stochastic Gradient Descent with Momentum; publisher=Towards Data Science (Medium); year=2018; url=https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d">
<meta name="citation_reference" content="author=Axatov A.R.; author=Rashidov A.E.; author=Nazarov F.M.; title=Real-Time Big Data Processing Based on a Distributed Computing Mechanism in a Single Server; book=Stochastic Processes and Their Applications in Artificial Intelligence; publisher=IGI Global; year=2023; doi=10.4018/978-1-6684-7679-6.ch009">
<meta name="citation_reference" content="title=Stochastic gradient descent; publisher=Wikipedia; url=https://en.wikipedia.org/wiki/Stochastic_gradient_descent">
<meta name="citation_reference" content="author=Rashidov A.; author=Akhatov A.; author=Nazarov F.; title=The Same Size Distribution of Data Based on Unsupervised Clustering Algorithms; book=Advances in Artificial Systems for Logistics Engineering III (LNDECT, volume 180) (ICAILE 2023); pages=437‚Äì447; year=2023; doi=10.1007/978-3-031-36115-9_40">
<meta name="citation_reference" content="author=Mehmood, F.; author=Ahmad, S.; author=Whangbo, T. K.; title=An efficient optimization technique for training deep neural networks; journal=Mathematics; volume=11; issue=6; year=2023; article=1360; doi=10.3390/math11061360">
<meta name="citation_reference" content="author=Akhatov A.R.; author=Rashidov A.E.; title=Machine Learning asosida taqsimlangan ma‚Äòlumotlar bazasi sonini optimallashtirish; conference=Xalqaro ilmiy texnik konferensiya; year=2022; pages=110‚Äì112">
<meta name="citation_reference" content="author=Rashidov A.; author=Akhatov A.; author=Aminov I.; author=Mardonov D.; title=Distribution of data flows in distributed systems using hierarchical clustering; conference=International Conference on Artificial Intelligence and Information Technologies (ICAIIT 2023); location=Samarkand; year=2023">


</head>
<body>
  <h1>USE OF OPTIMIZERS IN MODELS</h1>
  <p><strong>Authors:</strong> A. D. Madaminjonov (Namangan State University, Uzbekistan),  
  A. E. Rashidov (Samarkand State University, Uzbekistan)</p>
  <p><strong>Published:</strong> 2024, Proceedings of the XVI International Scientific-Practical Conference  
  ‚ÄúInnovative teaching techniques in physics, mathematics, vocational and mechanical training‚Äù</p>

  <h2>Abstract</h2>
  <p>
    In this study, we investigated the effect of different optimizers on the accuracy of a deep learning model using image data. 
    Optimizers such as SGD, Adam, RMSProp, and modified Adam were compared on CIFAR-10 and CIFAR-100 datasets with 
    VGG16, ResNet, and DenseNet architectures. Results show that the proposed method improves accuracy and reduces 
    training time compared to baseline optimizers.
  </p>

  <p>
    <a href="maqola3.pdf" target="_blank">üìÑ Download Full Text (PDF)</a>
  </p>
</body>
</html>
